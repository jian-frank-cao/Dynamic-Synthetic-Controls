n.datasets = nrow(df2)/length(t.interval)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
f.value = var.new/var.original
f.value = round(f.value, 4)
f.value
p.value = pf(f.value, n.datasets - 1,
n.datasets - 1, lower.tail = TRUE)
p.value = round(p.value, 4)
p.value
n.datasets
## California Tobacco Data -----------------------------------------------------
load("./data/smoking.rda")
prop99 = read.csv("./data/prop99.csv")
exclude_states = c("Massachusetts", "Arizona", "Oregon", "Florida",
"Alaska", "Hawaii", "Maryland", "Michigan",
"New Jersey", "New York",
"Washington", "District of Columbia")
include_states = sort(setdiff(unique(prop99$LocationDesc),
exclude_states))
states = data.frame(id = 1:length(include_states),
unit = include_states)
smoking = smoking %>% mutate_all(as.numeric)
colnames(smoking)[1:3] = c("id", "time", "value")
smoking = right_join(states, smoking, by = "id")
smoking = smoking %>%
mutate(value_raw = value,
age15to24 = age15to24*100)
data = smoking
# rescale
df.rescale = data %>%
filter(time <= 1989) %>%
group_by(unit) %>%
summarise(value.min = min(value),
value.max = max(value)) %>%
ungroup()
mean.diff = mean(df.rescale$value.max - df.rescale$value.min)
df.rescale = df.rescale %>%
mutate(
multiplier = mean.diff/(value.max - value.min)
)
data = left_join(data, df.rescale, by = "unit")
data = data %>%
mutate(
value.bak = value_raw,
value_raw = (value_raw - value.min)*multiplier,
value = value_raw
)
## Placebo v2 ------------------------------------------------------------------
results = readRDS("./data/res_tobacco_1019.Rds")
mse = future_map2(
results,
names(results),
~{
item = .x
id = .y
item$mse %>% mutate(id = id)
}
) %>%
do.call("rbind", .) %>%
filter(unit != "California")
units = unique(mse$unit)
opt.grid = data.frame(unit = units, id = 0)
for (i in 1:nrow(opt.grid)) {
target = opt.grid$unit[i]
scores = mse %>%
filter(unit != target) %>%
group_by(id) %>%
summarise(percent = mean(log.ratio < 0),
p.value = t.test(log.ratio)$p.value)
max.percent = which(scores$percent == max(scores$percent))
min.p = which(scores$p.value[max.percent] == min(scores$p.value[max.percent])[1])[1]
opt.grid[i,2] = as.numeric(scores$id[max.percent[min.p]])
}
tasks = unique(opt.grid$id)
tasks
# parameters
filter.width.range = (1:9)*2+3
k.range = 4:9
step.pattern.range = list(
# symmetricP0 = dtw::symmetricP0, # too bumpy
# symmetricP05 = dtw::symmetricP05,
symmetricP1 = dtw::symmetricP1,
symmetricP2 = dtw::symmetricP2,
# asymmetricP0 = dtw::asymmetricP0, # too bumpy
# asymmetricP05 = dtw::asymmetricP05,
asymmetricP1 = dtw::asymmetricP1,
asymmetricP2 = dtw::asymmetricP2,
typeIc = dtw::typeIc,
# typeIcs = dtw::typeIcs,
# typeIIc = dtw::typeIIc,  # jumps
# typeIIIc = dtw::typeIIIc, # jumps
# typeIVc = dtw::typeIVc,  # jumps
typeId = dtw::typeId,
# typeIds = dtw::typeIds,
# typeIId = dtw::typeIId, # jumps
mori2006 = dtw::mori2006
)
search.grid = expand.grid(filter.width.range, k.range,
names(step.pattern.range)) %>%
`colnames<-`(c("filter.width", "k", "step.pattern"))
tasks = cbind(data.frame(id = tasks),
search.grid[tasks,])
grid.search.parallel = FALSE
args.TFDTW = list(buffer = 0, match.method = "fixed",
dist.quant = 0.95,
window.type = "none",
## other
norm.method = "t",
step.pattern2 = dtw::asymmetricP2,
n.burn = 3, n.IQR = 3,
ma = 3, ma.na = "original",
default.margin = 3,
n.q = 1, n.r = 1)
args.synth = list(predictors = NULL,
special.predictors =
expression(list(
list(dep.var, 1988, c("mean")),
list(dep.var, 1980, c("mean")),
list(dep.var, 1975, c("mean")),
list("beer", 1984:1988, c("mean")),
list("lnincome", 1980:1988, c("mean")),
list("age15to24", 1980:1988, c("mean")),
list("retprice", 1980:1988, c("mean"))
)),
time.predictors.prior = 1970:1988,
time.optimize.ssr = 1970:1988)
args.TFDTW.synth = list(start.time = 1970, end.time = 2000, treat.time = 1989,
args.TFDTW = args.TFDTW, args.synth = args.synth,
## 2nd
n.mse = 10,
## other
plot.figures = TRUE,
plot.path = "./figures/",
legend.pos = c(0.3, 0.3))
args.TFDTW.synth.all.units = list(target = "California",
# data = data,
args.TFDTW.synth = args.TFDTW.synth,
detailed.output = TRUE,
## 2nd
all.units.parallel = TRUE)
results = tasks %>%
split(., seq(nrow(tasks))) %>%
set_names(tasks$id) %>%
map(
~{
search = .
args.TFDTW.synth.all.units[["data"]] = data
results = SimDesign::quiet(
grid.search(filter.width.range = search$filter.width,
k.range = search$k,
step.pattern.range = step.pattern.range[search$step.pattern],
args.TFDTW.synth.all.units = args.TFDTW.synth.all.units,
grid.search.parallel = grid.search.parallel)
)
results
}
)
# plot figures
df = future_map2(
results[as.character(opt.grid$id)],
units %>% as.list,
~{
item = .x[[1]]
unit = .y
value = item$results.TFDTW.synth[[unit]]$res.synth.raw$value
gap_original = item$results.TFDTW.synth[[unit]]$gap.raw
gap_new = item$results.TFDTW.synth[[unit]]$gap.TFDTW
data.frame(unit = unit,
time = 1970:2000,
value = value,
gap_original = gap_original,
gap_new = gap_new)
}
) %>%
do.call("rbind", .)
t.interval = 1990:1999
df2 = df %>% filter(time %in% t.interval)
n.t = length(t.interval)
n.datasets = nrow(df2)/length(t.interval)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
f.value = var.new/var.original
f.value = round(f.value, 4)
p.value = pf(f.value, n.datasets - 1,
n.datasets - 1, lower.tail = TRUE)
p.value = round(p.value, 4)
f.value
var.new
var.original
View(df)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]]
var.original
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]]
var.new
View(df2)
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]]
var.new
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
f.value = var.new/var.original
f.value = round(f.value, 4)
p.value = pf(f.value, n.datasets - 1,
n.datasets - 1, lower.tail = TRUE)
p.value = round(p.value, 4)
f.value
t.interval = 1990:1996
df2 = df %>% filter(time %in% t.interval)
n.t = length(t.interval)
n.datasets = nrow(df2)/length(t.interval)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
f.value = var.new/var.original
f.value = round(f.value, 4)
p.value = pf(f.value, n.datasets - 1,
n.datasets - 1, lower.tail = TRUE)
p.value = round(p.value, 4)
f.value
t.interval = 1990:1995
df2 = df %>% filter(time %in% t.interval)
n.t = length(t.interval)
n.datasets = nrow(df2)/length(t.interval)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
f.value = var.new/var.original
f.value = round(f.value, 4)
p.value = pf(f.value, n.datasets - 1,
n.datasets - 1, lower.tail = TRUE)
p.value = round(p.value, 4)
f.value
t.interval = 1990:1999
df2 = df %>% filter(time %in% t.interval)
n.t = length(t.interval)
n.datasets = nrow(df2)/length(t.interval)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new,na.rm = T)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
f.value = var.new/var.original
f.value = round(f.value, 4)
p.value = pf(f.value, n.datasets - 1,
n.datasets - 1, lower.tail = TRUE)
p.value = round(p.value, 4)
f.value
p.value
n.datasets
library(checkpoint)
checkpoint("2022-04-01")
library(tidyverse)
library(furrr)
plan(multisession, workers = 8)
options(future.rng.onMisuse="ignore")
options(stringsAsFactors = FALSE)
source("./R/misc.R")
source("./R/TFDTW.R")
source("./R/synth.R")
source("./R/implement.R")
source("./R/grid.search.R")
set.seed(20220407)
## Basque Terrorism Data -------------------------------------------------------
data(basque, package = "Synth")
data = basque
colnames(data)[1:4] = c("id", "unit", "time", "value")
data = data %>% mutate(invest_ratio = invest/value,
value_raw = value)
# rescale
df.rescale = data %>%
filter(time <= 1970) %>%
group_by(unit) %>%
summarise(value.min = min(value),
value.max = max(value)) %>%
ungroup()
mean.diff = mean(df.rescale$value.max - df.rescale$value.min)
df.rescale = df.rescale %>%
mutate(
multiplier = mean.diff/(value.max - value.min)
)
data = left_join(data, df.rescale, by = "unit")
data = data %>%
mutate(
value.bak = value_raw,
value_raw = (value_raw - value.min)*multiplier,
value = value_raw
)
## Placebo v2 ------------------------------------------------------------------
results = readRDS("./data/res_basque_1019.Rds")
mse = future_map2(
results,
names(results),
~{
item = .x
id = .y
item$mse %>% mutate(id = id)
}
) %>%
do.call("rbind", .) %>%
filter(unit != "Basque Country (Pais Vasco)")
units = unique(mse$unit)
opt.grid = data.frame(unit = units, id = 0)
for (i in 1:nrow(opt.grid)) {
target = opt.grid$unit[i]
scores = mse %>%
filter(unit != target) %>%
group_by(id) %>%
summarise(percent = mean(log.ratio < 0),
p.value = t.test(log.ratio)$p.value)
max.percent = which(scores$percent == max(scores$percent))
min.p = which(scores$p.value[max.percent] == min(scores$p.value[max.percent])[1])[1]
opt.grid[i,2] = as.numeric(scores$id[max.percent[min.p]])
}
opt.grid
tasks = unique(opt.grid$id)
# parameters
filter.width.range = (1:9)*2+3
k.range = 4:9
step.pattern.range = list(
# symmetricP0 = dtw::symmetricP0, # too bumpy
# symmetricP05 = dtw::symmetricP05,
symmetricP1 = dtw::symmetricP1,
symmetricP2 = dtw::symmetricP2,
# asymmetricP0 = dtw::asymmetricP0, # too bumpy
# asymmetricP05 = dtw::asymmetricP05,
asymmetricP1 = dtw::asymmetricP1,
asymmetricP2 = dtw::asymmetricP2,
typeIc = dtw::typeIc,
# typeIcs = dtw::typeIcs,
# typeIIc = dtw::typeIIc,  # jumps
# typeIIIc = dtw::typeIIIc, # jumps
# typeIVc = dtw::typeIVc,  # jumps
typeId = dtw::typeId,
# typeIds = dtw::typeIds,
# typeIId = dtw::typeIId, # jumps
mori2006 = dtw::mori2006
)
search.grid = expand.grid(filter.width.range, k.range,
names(step.pattern.range)) %>%
`colnames<-`(c("filter.width", "k", "step.pattern"))
tasks = cbind(data.frame(id = tasks),
search.grid[tasks,])
grid.search.parallel = FALSE
tasks
args.TFDTW = list(buffer = 0, match.method = "fixed",
dist.quant = 0.95,
window.type = "none",
## other
norm.method = "t",
step.pattern2 = dtw::asymmetricP2,
n.burn = 3, n.IQR = 3,
ma = 3, ma.na = "original",
default.margin = 3,
n.q = 1, n.r = 1)
args.synth = list(predictors = NULL,
special.predictors =
expression(list(
list(dep.var, 1960:1969, c("mean")),
list("invest_ratio", 1964:1969, c("mean")),
list("popdens", 1969, c("mean")),
list("sec.agriculture", 1961:1969, c("mean")),
list("sec.energy", 1961:1969, c("mean")),
list("sec.industry", 1961:1969, c("mean")),
list("sec.construction", 1961:1969, c("mean")),
list("sec.services.venta", 1961:1969, c("mean")),
list("sec.services.nonventa", 1961:1969, c("mean")),
list("school.illit", 1964:1969, c("mean")),
list("school.prim", 1964:1969, c("mean")),
list("school.med", 1964:1969, c("mean")),
list("school.high", 1964:1969, c("mean")),
list("school.post.high", 1964:1969, c("mean"))
)),
time.predictors.prior = 1955:1969,
time.optimize.ssr = 1955:1969)
args.TFDTW.synth = list(start.time = 1955, end.time = 1997, treat.time = 1970,
args.TFDTW = args.TFDTW, args.synth = args.synth,
## 2nd
n.mse = 10,
## other
plot.figures = TRUE,
plot.path = "./figures/",
legend.pos = c(0.3, 0.3))
args.TFDTW.synth.all.units = list(target = "Basque Country (Pais Vasco)",
# data = data,
args.TFDTW.synth = args.TFDTW.synth,
detailed.output = TRUE,
## 2nd
all.units.parallel = TRUE)
results = tasks %>%
split(., seq(nrow(tasks))) %>%
set_names(tasks$id) %>%
map(
~{
search = .
args.TFDTW.synth.all.units[["data"]] = data
results = SimDesign::quiet(
grid.search(filter.width.range = search$filter.width,
k.range = search$k,
step.pattern.range = step.pattern.range[search$step.pattern],
args.TFDTW.synth.all.units = args.TFDTW.synth.all.units,
grid.search.parallel = grid.search.parallel)
)
results
}
)
# plot figures
df = future_map2(
results[as.character(opt.grid$id)],
units %>% as.list,
~{
item = .x[[1]]
unit = .y
value = item$results.TFDTW.synth[[unit]]$res.synth.raw$value
gap_original = item$results.TFDTW.synth[[unit]]$gap.raw
gap_new = item$results.TFDTW.synth[[unit]]$gap.TFDTW
data.frame(unit = unit,
time = 1955:1997,
value = value,
gap_original = gap_original,
gap_new = gap_new)
}
) %>%
do.call("rbind", .)
View(df)
t.interval = 1971:1980
df2 = df %>% filter(time %in% t.interval)
n.t = length(t.interval)
n.datasets = nrow(df2)/length(t.interval)
var.original = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_original)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.new = df2 %>% group_by(unit) %>%
summarise(variance = var(gap_new)*(n.t - 1)) %>%
ungroup %>%
.[["variance"]] %>%
sum(., na.rm = T)/(n.datasets*(n.t - 1))
var.original
var.new
View(df2)
df2 = df2 %>%
group_by(unit) %>%
mutate(mse.sc = mean(gap_original^2),
mse.dsc = mean(gap_new^2),
log.ratio = log(mse.dsc/mse.sc))
t.test(df2$log.ratio)
View(df2)
df2 = df2 %>%
group_by(unit) %>%
summarise(mse.sc = mean(gap_original^2),
mse.dsc = mean(gap_new^2)) %>%
mutate(log.ratio = log(mse.dsc/mse.sc))
View(df2)
t.test(df2$log.ratio)
t.test(rep(df2$log.ratio, 2))
t.test(rep(df2$log.ratio, 3))
df2 = df %>% filter(time %in% t.interval)
mean(df2$gap_original)
mean(df2$gap_new)
